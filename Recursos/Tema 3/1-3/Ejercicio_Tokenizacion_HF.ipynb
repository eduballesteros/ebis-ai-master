{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "041bf98c",
   "metadata": {},
   "source": [
    "# üß™ Ejercicio 3 ‚Äì Exploraci√≥n de Tokenizaci√≥n con Hugging Face\n",
    "üéØ **Objetivo:** Analizar c√≥mo diferentes modelos tokenizan el mismo texto y comprender el papel de los tokens especiales y la codificaci√≥n en IDs.\n",
    "\n",
    "üì¶ **Herramientas a usar:**\n",
    "- `transformers.AutoTokenizer` ‚Üí para cargar distintos tokenizadores y explorar su funcionamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f94221",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets tokenizers matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c618a06",
   "metadata": {},
   "source": [
    "### üß© Paso 1: Cargar el tokenizador del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ddec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Cargar tokenizador BERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "print(\"Tokenizador BERT cargado correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6156c614",
   "metadata": {},
   "source": [
    "### üß© Paso 2: Tokenizar un texto de ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1bfedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I can't wait to use ü§ñ in my projects!\"\n",
    "\n",
    "tokens = tokenizer.tokenize(text)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(\"Texto original:\")\n",
    "print(text)\n",
    "print(\"\\nTokens generados:\")\n",
    "print(tokens)\n",
    "print(\"\\nIDs de los tokens:\")\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938bebf9",
   "metadata": {},
   "source": [
    "### üîÅ Paso 3: Comparar con otro modelo (ej. GPT-2 o Mistral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e32a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizador alternativo: GPT-2\n",
    "alt_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "alt_tokens = alt_tokenizer.tokenize(text)\n",
    "alt_ids = alt_tokenizer.convert_tokens_to_ids(alt_tokens)\n",
    "\n",
    "print(\"\\nTokens con GPT-2:\")\n",
    "print(alt_tokens)\n",
    "print(\"IDs con GPT-2:\")\n",
    "print(alt_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1466782a",
   "metadata": {},
   "source": [
    "### üìä Paso 4: ¬øCu√°l tokeniza en m√°s fragmentos? ¬øQu√© diferencias ves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70122256",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Longitud tokens BERT: {len(tokens)}\")\n",
    "print(f\"Longitud tokens GPT-2: {len(alt_tokens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5e4dab",
   "metadata": {},
   "source": [
    "### üß† OPCIONAL ‚Äì Prueba tu propio texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d03af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_text = input(\"Introduce un texto: \")\n",
    "tok1 = tokenizer.tokenize(user_text)\n",
    "tok2 = alt_tokenizer.tokenize(user_text)\n",
    "\n",
    "print(\"\\nBERT tokens:\", tok1)\n",
    "print(\"GPT-2 tokens:\", tok2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e243484",
   "metadata": {},
   "source": [
    "# EJERCICIO PR√ÅCTICO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f2c0d6",
   "metadata": {},
   "source": [
    "### ‚úÖ Instrucciones:\n",
    "### 1. Introduce una frase que se te ocurra.\n",
    "### 2. Elige dos modelos distintos de la Hugging Face Hub (por ejemplo: \"bert-base-uncased\", \"roberta-base\", \"gpt2\", \"mistralai/Mistral-7B-Instruct-v0.2\", etc.).\n",
    "### 3. Compara c√≥mo se tokeniza en cada uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bdabe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß© Ejercicio: Compara la tokenizaci√≥n entre dos modelos\n",
    "# üéØ Objetivo: Introducir una frase y comparar c√≥mo dos modelos diferentes la tokenizan.\n",
    "\n",
    "# 1Ô∏è‚É£ Pide al usuario que introduzca una frase.\n",
    "#    Usa la funci√≥n `input()` para capturar la frase.\n",
    "\n",
    "# 2Ô∏è‚É£ Pide al usuario que introduzca los nombres de dos modelos de Hugging Face.\n",
    "#    Por ejemplo: \"bert-base-uncased\" y \"gpt2\".\n",
    "\n",
    "# 3Ô∏è‚É£ Carga los tokenizadores de los modelos seleccionados:\n",
    "#    - Usa `AutoTokenizer.from_pretrained()` para cargar cada modelo.\n",
    "\n",
    "# 4Ô∏è‚É£ Tokeniza la frase con ambos modelos:\n",
    "#    - Usa el m√©todo `tokenize()` para dividir la frase en tokens.\n",
    "\n",
    "# 5Ô∏è‚É£ Muestra los resultados:\n",
    "#    - Imprime los tokens generados por cada modelo.\n",
    "#    - Muestra tambi√©n la cantidad de tokens generados.\n",
    "\n",
    "# üí° Pista: Usa `len()` para contar el n√∫mero de tokens.\n",
    "\n",
    "# Escribe tu c√≥digo aqu√≠:\n",
    "# frase = ...\n",
    "# modelo_1 = ...\n",
    "# modelo_2 = ...\n",
    "# tok1 = ...\n",
    "# tok2 = ...\n",
    "# tokens_1 = ...\n",
    "# tokens_2 = ...\n",
    "# print(f\"...\")\n",
    "# print(f\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a936c8",
   "metadata": {},
   "source": [
    "# Soluci√≥n (Click para revelar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d66c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "frase = input(\"Escribe tu propia frase para comparar tokenizaci√≥n:\\n\")\n",
    "\n",
    "modelo_1 = input(\"Modelo 1 (ej. bert-base-uncased): \")\n",
    "modelo_2 = input(\"Modelo 2 (ej. mistralai/Mistral-7B-Instruct-v0.2): \")\n",
    "\n",
    "tok1 = AutoTokenizer.from_pretrained(modelo_1)\n",
    "tok2 = AutoTokenizer.from_pretrained(modelo_2)\n",
    "\n",
    "tokens_1 = tok1.tokenize(frase)\n",
    "tokens_2 = tok2.tokenize(frase)\n",
    "\n",
    "print(f\"\\nüîπ {modelo_1}:\\n{tokens_1} ({len(tokens_1)} tokens)\")\n",
    "print(f\"\\nüî∏ {modelo_2}:\\n{tokens_2} ({len(tokens_2)} tokens)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
