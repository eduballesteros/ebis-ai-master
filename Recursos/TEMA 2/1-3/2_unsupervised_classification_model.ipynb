{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8yOw8Y4VHoA"
   },
   "source": [
    "# Ejemplo práctico de un modelo NO supervisado de clasificación\n",
    "---\n",
    "\n",
    "Autor: Manuel Díaz Bendito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uM1vD7r898zN"
   },
   "source": [
    "---\n",
    "\n",
    "El objetivo de este notebook, dado el dataset [Wine](https://archive.ics.uci.edu/dataset/109/wine), desarrollar un modelo de clusterización no supervisado para ver si somos capaces de identificar los 3 tipos distintos de vino que hay presentes en los datos explorados. Si bien se trata de un dataset etiquetado, es un muy buen ejercicio a llevar a cabo para mostar las virtudes de la reducción de dimensionalidad, de los modelos más modernos de clusterización, y las capacidades de visualización y entendimiento que pueden utilizarse para un análisis posterior.\n",
    "\n",
    "El desarrollo del notebook se compone de 4 pasos fundamentales:\n",
    "\n",
    "* La carga, preparación y realización del Exploratory Data Analysis (EDA) de los datos.\n",
    "* El procesado e ingeniería de características de estos datos.\n",
    "* El entrenamiento y visualización de la clusterización o segmentación de los datos.\n",
    "* La validación de los resultados obtenidos, utilizando las etiquetas del dataset, y la conclusión final del desarrollo.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KWppwtouaG0J",
    "tags": []
   },
   "source": [
    "# 0 - Instalaciones necesarias e importación de librerías utilizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6z9O6sj-98zS",
    "tags": []
   },
   "source": [
    "## Instalación de librerías\n",
    "---\n",
    "Además de la librería propia del dataset objeto de estudio, se han instalado las librerías de [UMAP](https://umap-learn.readthedocs.io/en/latest/) y de [HBDSCAN](https://pypi.org/project/hdbscan/), que se utilizarán para la segmentación de los datos y su posterior visualización, y que funcionan muy bien juntas.\n",
    "\n",
    "Si durante la fase de importación, el usuario se encuentra con algún error de importación, deberá añadir la instalación de dicha librería en este bloque.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzUyit93aO7K"
   },
   "source": [
    "## Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XyJBxDEgnnJx"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import hdbscan\n",
    "import umap.umap_ as umap\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import random\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzVszatzaQ7z"
   },
   "source": [
    "# 1 - Carga, preparación y EDA de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14-FDUWY98zY"
   },
   "source": [
    "## 1.1 - Carga del dataset\n",
    "---\n",
    "La carga del dataset se realiza utilizando la librería desarrolada por la Universidad Pública de Irvine.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KhTtmH0naqiU"
   },
   "outputs": [],
   "source": [
    "# fetch dataset\n",
    "wine = fetch_ucirepo(id=109) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "df_train_raw = wine.data.features \n",
    "df_target_raw = wine.data.targets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1700822386929,
     "user": {
      "displayName": "Manuel Díaz",
      "userId": "13859083903242049446"
     },
     "user_tz": -60
    },
    "id": "rLxAF58VdOXU",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "f3a5b9fb-ba09-40c8-87b6-4928c69e3638",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNQiv2s8b18b",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1.2 - Preparación del dataset\n",
    "---\n",
    "En este punto, se unen datos y las etiquetas (descargados por separado en la carga del dataset).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1700822386929,
     "user": {
      "displayName": "Manuel Díaz",
      "userId": "13859083903242049446"
     },
     "user_tz": -60
    },
    "id": "bPKuflthOZjc",
    "outputId": "77a5e30d-2d60-4071-e473-9d9e7ab636cf"
   },
   "outputs": [],
   "source": [
    "# Imprimimos por pantalla cómo es la variable objetivo inicialmente.\n",
    "df_target_raw.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T7acjq-aOtpW"
   },
   "outputs": [],
   "source": [
    "# Unimos datos y etiquetas en el mismo dataframe y aplicamos el mapeo de la variable objetivo.\n",
    "df_train_raw['target'] = df_target_raw['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1700822386929,
     "user": {
      "displayName": "Manuel Díaz",
      "userId": "13859083903242049446"
     },
     "user_tz": -60
    },
    "id": "gDcZb_18O_Lg",
    "outputId": "ef2fa72b-1902-4460-8004-3de27669d0fc"
   },
   "outputs": [],
   "source": [
    "# Imprimimos por pantalla el nuevo target y su presencia (tanto por 1) en el dataset.\n",
    "df_train_raw['target'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBbVXuNDb6So"
   },
   "source": [
    "## 1.3 - EDA\n",
    "---\n",
    "En este punto, se realiza el EDA del dataset propuesto. En este desarrollo, se ha dividido el EDA en dos puntos:\n",
    "* Una exploración preliminar de las variables numéricas.\n",
    "* Una exploración gráfica de las variables numéricas.\n",
    "\n",
    "Como punto previo a todo el análisis, las variables sobre las que realizar el EDA son las siguientes (las definiciones son aproximaciones en cuanto al contexto y la documentación disponible):\n",
    "* Alcohol: porcentaje de alcohol del vino - **numérica**\n",
    "* Malicacid: concentración de ácido málico (un ácido orgánico natural) - **numérica**\n",
    "* Ash: cantidad de cenizas (minerales) en el vino después de quemarlo - **numérica**\n",
    "* Alcalinity_of_ash: alcalinidad de las cenizas (capacidad de neutralizar ácidos) - **numérica**\n",
    "* Magnesium: contenido de magnesio (en partes por millón) - **numérica**\n",
    "* Total_phenols: concentración total de compuestos fenólicos (afectan sabor y color) - **numérica**\n",
    "* Flavanoids: subgrupo de fenoles relacionados al sabor y antioxidantes - **numérica**\n",
    "* Nonflavanoid_phenols: otros fenoles que no son flavonoides - **numérica**\n",
    "* Proanthocyanins: tipo de tanino (astringencia y color del vino) - **numérica**\n",
    "* Color_intensity: intensidad del color del vino - **numérica**\n",
    "* Hue: tono de color (matiz) del vino - **numérica**\n",
    "* 0D280_0D315_of_diluted_wines: relación de absorbancia, mide fenoles y calidad - **numérica**\n",
    "* Proline: cantidad de prolina (aminoácido relacionado con el aroma y sabor del vino) - **numérica**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-ifXaaDaYzT",
    "tags": []
   },
   "source": [
    "### 1.3.1 - Exploración preliminar de las variables numéricas\n",
    "---\n",
    "En este punto nos valemos del método describe para ver las métricas más inmediatas de las variables numérias.\n",
    "Asimismo, obtenemos la matriz de correlación entre ellas.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1700822386929,
     "user": {
      "displayName": "Manuel Díaz",
      "userId": "13859083903242049446"
     },
     "user_tz": -60
    },
    "id": "R5upP0Q4OLLY",
    "outputId": "38de2525-37a2-4944-c58c-cf69b924908a"
   },
   "outputs": [],
   "source": [
    "df_train_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1700822386929,
     "user": {
      "displayName": "Manuel Díaz",
      "userId": "13859083903242049446"
     },
     "user_tz": -60
    },
    "id": "xMsfndyJnFS5",
    "outputId": "ae95525e-6a77-4514-ff26-09fc3bc6de79"
   },
   "outputs": [],
   "source": [
    "df_train_raw.corr(numeric_only = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRgjDmVO98ze"
   },
   "source": [
    "---\n",
    "La primera lectura de este análisis preliminar nos muestra que, en principio, no hay ninguna variable numérica con valores extraños teniendo en cuenta la información que representa. No hay valores negativos, ni disonantes en ninguno de los campos.\n",
    "\n",
    "Respecto a la correlación, el target parece guardar especial correlación numérica con `Total_phenols`, `Flavanoids` y `0D280_0D315_of_diluted_wines`. Un análisis posterior con un equipo técnico de laboratorio podría arrojar algo más de información al respecto de este hecho.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dmmz9827bLnS",
    "tags": []
   },
   "source": [
    "### 1.3.2 - Exploración gráfica de las variables numéricas\n",
    "---\n",
    "Para este punto, y por comodidad, se ha desarrollado la función **plot_num_feat**. Esta función grafica, para las agrupaciones de la característica numérica elegidas por el usuario, el porcentaje de clase 0 y de clase 1 acumulados en un diagrama de barras. Además, superupesto al diagrama de barras, se grafica en un diagrama de líneas el porcentaje de cada categoría sobre el total. Asimismo, si el lector lo desea, se puede mostrar por pantalla un box plot de la característica para ayudar en el análisis.\n",
    "\n",
    "El código de la función está comentado para su comprensión.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Abbz_zA1Xax3"
   },
   "outputs": [],
   "source": [
    "def plot_num_feat(df, feat, bins, print_box = False):\n",
    "  '''\n",
    "  Función encargada de mostrar un gráfico con, dado bien un número de\n",
    "  particiones o los puntos de corte de una variable numérica, el % de clases\n",
    "  de cada agrupación y su presencia total en el dataset.\n",
    "\n",
    "  Parámetros de entrada:\n",
    "    - df: dataframe en el que se encuentran los datos a analizar.\n",
    "    - feature: nombre de la característica a analizar.\n",
    "    - bins: valor numérico con el número de particiones o lista con los puntos\n",
    "    de corte deseados para la variable numérica.\n",
    "    - print_box: bandera que, si se activa, muestra un diagrama de caja de la\n",
    "    característica numérica analizada.\n",
    "\n",
    "  La función no tiene parámetros de retorno.\n",
    "  '''\n",
    "\n",
    "  # Creamos un nuevo dataframe con las particiones requeridas por el usuario\n",
    "  df_binned = df[[feat, 'target']].copy()\n",
    "  df_binned['bins'] = pd.cut(df[feat], bins=bins)\n",
    "\n",
    "  # Calculamos la distribución de clases por grupo\n",
    "  df_grouped = df_binned.groupby('bins')['target'].value_counts(normalize=True).unstack(fill_value=0) * 100\n",
    "\n",
    "  # Calculamos el % de presencia de cada agrupación\n",
    "  df_counts = df_binned['bins'].value_counts().sort_index()\n",
    "  df_grouped['% presencia'] = df_counts / df_counts.sum() * 100\n",
    "\n",
    "  # Graficamos el diagrama de barras del % de clases de cada agrupación\n",
    "  ax = df_grouped.drop(columns='% presencia').plot(kind='bar',\n",
    "                                                   stacked=True,\n",
    "                                                   figsize=(7,7),\n",
    "                                                   title='% de clases en cada grupo de la característica ' + feat)\n",
    "\n",
    "  # Graficamos el diagrama de línea del % de presencia de cada agrupación\n",
    "  df_grouped['% presencia'].plot(kind='line', color='red', linewidth=1.5, linestyle='-.', marker='o', ax=ax, rot=90)\n",
    "\n",
    "  ax.set_xlabel('Grupos de la característica ' + feat)\n",
    "  ax.set_ylabel('%')\n",
    "  ax.legend(['% presencia'] + [f'% clase {c}' for c in df_grouped.drop(columns='% presencia').columns])\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "  # Si el usuario lo desea, mostramos un diagrama de caja de la característica\n",
    "  if print_box:\n",
    "    df[feat].plot(kind='box')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zgqk4MW4iS7"
   },
   "source": [
    "#### Alcohol\n",
    "---\n",
    "La variable alcohol muestra un patrón claro: a medida que aumenta la graduación alcohólica del vino, crece de forma progresiva la proporción de muestras de la clase 1, mientras que las clases 2 y 3 dominan en los niveles más bajos de alcohol. No se observan valores atípicos extremos en el diagrama de caja, pero existe una leve asimetría positiva (hacia valores altos).\n",
    "\n",
    "Concretamente, a partir de los 13.5 grados, la clase 1 empieza a ser mayoritaria, y a partir de 14 grados prácticamente monopoliza el conjunto.\n",
    "\n",
    "De esta forma, mantendremos esta variable tal cual, pues su capacidad discriminativa es alta.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "executionInfo": {
     "elapsed": 918,
     "status": "ok",
     "timestamp": 1700822393179,
     "user": {
      "displayName": "Manuel Díaz",
      "userId": "13859083903242049446"
     },
     "user_tz": -60
    },
    "id": "jOTiJo8DkCK9",
    "outputId": "8b106c8a-a97f-4a92-c631-75c9907f7f75"
   },
   "outputs": [],
   "source": [
    "plot_num_feat(df_train_raw, 'Alcohol', bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxrMj3u140qU"
   },
   "source": [
    "#### Malicacid\n",
    "---\n",
    "La variable malic acid presenta una distribución amplia y dispersa, con bastantes valores extremos hacia niveles altos. Los vinos con valores bajos (menores a 2) tienden a pertenecer a la clase 1 y 2, mientras que los valores altos reflejan claramente la predominancia de la clase 3.\n",
    "\n",
    "No se observa un comportamiento estrictamente lineal, sino más bien zonas estables de predominio leve de ciertas clases.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 797
    },
    "executionInfo": {
     "elapsed": 1803,
     "status": "ok",
     "timestamp": 1700822394980,
     "user": {
      "displayName": "Manuel Díaz",
      "userId": "13859083903242049446"
     },
     "user_tz": -60
    },
    "id": "j7OZReihkIcR",
    "outputId": "9dfd588f-63d0-4d97-9cc5-84d27386faff"
   },
   "outputs": [],
   "source": [
    "plot_num_feat(df_train_raw, 'Malicacid', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4NgjKqb41Oc"
   },
   "source": [
    "#### Ash\n",
    "---\n",
    "La variable ash presenta una distribución compacta, sin valores atípicos fuertes. Se aprecia que los valores más bajos (1.3-2.0) favorecen levemente a la clase 2, pero las diferencias no son muy marcadas en valore superiores a 2.\n",
    "\n",
    "La presencia de clases es bastante homogénea a través de todos los valores superiores a 2, lo que indica una baja capacidad discriminativa individual.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 709
    },
    "executionInfo": {
     "elapsed": 1116,
     "status": "ok",
     "timestamp": 1700822396094,
     "user": {
      "displayName": "Manuel Díaz",
      "userId": "13859083903242049446"
     },
     "user_tz": -60
    },
    "id": "j_Eiioo4lGW8",
    "outputId": "88acaaef-cc7e-4bef-a745-e606ac5d18c0"
   },
   "outputs": [],
   "source": [
    "plot_num_feat(df_train_raw, 'Ash', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce5nPOUC41vD"
   },
   "source": [
    "#### Alcalinity_of_ash\n",
    "---\n",
    "Alcalinity of ash tiene un rango de valores amplio y muestra una ligera tendencia: los valores bajos (10-15) son más frecuentes en la clase 1, mientras que valores intermedios (15-25) no discriminan claramente. Existen algunos valores atípicos hacia valores altos. A partir del 25, se puede ver una evidente predominancia de la clase 2.\n",
    "\n",
    "No se observa una relación lineal, sino más bien una separación parcial en los extremos.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 762
    },
    "executionInfo": {
     "elapsed": 580,
     "status": "ok",
     "timestamp": 1700822396672,
     "user": {
      "displayName": "Manuel Díaz",
      "userId": "13859083903242049446"
     },
     "user_tz": -60
    },
    "id": "ONdRg-tcmAnU",
    "outputId": "c0e8293e-fcb7-4dca-f57d-e9a75c9440e1"
   },
   "outputs": [],
   "source": [
    "plot_num_feat(df_train_raw, 'Alcalinity_of_ash', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-RrReml242P6"
   },
   "source": [
    "#### Magnesium\n",
    "---\n",
    "La variable magnesium tiene una distribución razonablemente simétrica, aunque con algunos valores elevados considerados atípicos.\n",
    "\n",
    "Los niveles bajos (70-100) presentan casi toda la muestra de la clase 3, mientras que los intermedios (80-150) son los que prevalencen para la clas 1. La clase 2 se ve distribuida casi uniformemente a lo largo de toda la variable.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 744
    },
    "executionInfo": {
     "elapsed": 695,
     "status": "ok",
     "timestamp": 1700822397365,
     "user": {
      "displayName": "Manuel Díaz",
      "userId": "13859083903242049446"
     },
     "user_tz": -60
    },
    "id": "lrWfo5rrmQZe",
    "outputId": "dd8af8c2-4ee4-4f96-d144-a71d67c8773a"
   },
   "outputs": [],
   "source": [
    "plot_num_feat(df_train_raw, 'Magnesium', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6eZxpkA43Dv"
   },
   "source": [
    "#### Total_Phenols\n",
    "---\n",
    "Total phenols muestra una relación clara: vinos con altos niveles de fenoles totales (mayores a 2.5) tienden a pertenecer abrumadoramente a la clase 1.\n",
    "Los valores bajos (menores a 1.5) favorecen clases 2 y 3.\n",
    "\n",
    "No se detectan outliers preocupantes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "executionInfo": {
     "elapsed": 492,
     "status": "ok",
     "timestamp": 1700822397855,
     "user": {
      "displayName": "Manuel Díaz",
      "userId": "13859083903242049446"
     },
     "user_tz": -60
    },
    "id": "8d0QpMq2mYM9",
    "outputId": "50f6f5c5-f03b-46eb-9c82-94bbe71cef0f"
   },
   "outputs": [],
   "source": [
    "plot_num_feat(df_train_raw, 'Total_phenols', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flavanoids\n",
    "---\n",
    "La variable flavanoids presenta un comportamiento muy similar al de total phenols, aunque de forma aún más marcada.\n",
    "\n",
    "Niveles altos (más de 3) se asocian casi exclusivamente a clase 1.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_num_feat(df_train_raw, 'Flavanoids', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nonflavanoid_phenols\n",
    "---\n",
    "Nonflavanoid phenols tiene un rango muy estrecho y una distribución menos discriminativa. Sin embargo, valores elevados (>0.5) tienden a asociarse ligeramente a clase 2 y 3.\n",
    "\n",
    "Los niveles intermedios y bajos no permiten separación clara.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_num_feat(df_train_raw, 'Nonflavanoid_phenols', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proanthocyanins\n",
    "---\n",
    "La variable proanthocyanins muestra una clara separación entre las clases 1 y 3 a partir de valores rondando el 2.\n",
    "\n",
    "La clase 2 está presente uniformemente casi en la totalidad de la muestra.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_num_feat(df_train_raw, 'Proanthocyanins', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color_intensity\n",
    "---\n",
    "Color intensity presenta una separación evidente: vinos con coloraciones más intensas (mayores a 6) son mayoritariamente de la clase 3.\n",
    "\n",
    "La clase 1 domina en valores intermedios, mientras que la clase 2 predomina en colores menos intensos (<3).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_num_feat(df_train_raw, 'Color_intensity', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hue\n",
    "---\n",
    "La variable Hue presenta un comportamiento similar al de la coloración, pero intercambiando la clase 3 por la 2, y manteniendo el comportamiento de la clase 1.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_num_feat(df_train_raw, 'Hue', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0D280_0D315_of_diluted_wines\n",
    "---\n",
    "La variable OD280/OD315 es muy buena discriminadora: valores altos (por encima de 2.8) concentran la mayoría de la clase 1, mientras que valores bajos están más asociados a clase 3.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_num_feat(df_train_raw, '0D280_0D315_of_diluted_wines', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proline\n",
    "---\n",
    "La variable proline destaca como la mejor separadora: niveles bajos (menos de 600) son casi exclusivos de clase 2, intermedios de clase 3, y niveles muy altos (>1200) son dominio absoluto de la clase 1.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_num_feat(df_train_raw, 'Proline', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7vcpTBWbSQm"
   },
   "source": [
    "# 2 - Procesado e ingeniería de características\n",
    "---\n",
    "En este punto, se realiza el procesado previo a la ingeniería de características, y la ingeniería de características propiamente dicha. Esta ingeniería de características se ha realizado utilizando la información y los insights obtenidos del EDA (del que se ha decidido mantener todas las variables), y de la tipología del modelo de ML a utilizar, por el cual se han tomado las siguientes decisiones:\n",
    "\n",
    "* Se rellenarán todos aquellos NaNs presentes en el dataset con la media de cada columna (HDBSCAN no trabaja con NaNs)\n",
    "\n",
    "* Se estandarizarán todas las variables, para que cuando se haga la reducción de la dimensionalidad, mantengamos todas las variables en el mismo rango de trabajo, quitando outliers y paliando valores atípicos.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HBnOlgDDajdj"
   },
   "outputs": [],
   "source": [
    "# Copiamos el dataset original para no realizar transformaciones sobre este.\n",
    "df_train = df_train_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2H1zTcectu3"
   },
   "source": [
    "## 2.1 - Procesado de los datos e ingeniería de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaramos las características a utilizar en el entrenamiento del modelo, así\n",
    "# como el target del mismo.\n",
    "feats2use = [\n",
    " 'Alcohol',\n",
    " 'Malicacid',\n",
    " 'Ash',\n",
    " 'Alcalinity_of_ash',\n",
    " 'Magnesium',\n",
    " 'Total_phenols',\n",
    " 'Flavanoids',\n",
    " 'Nonflavanoid_phenols',\n",
    " 'Proanthocyanins',\n",
    " 'Color_intensity',\n",
    " 'Hue',\n",
    " '0D280_0D315_of_diluted_wines',\n",
    " 'Proline',\n",
    " 'target'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos la selección de las características a utilizar del dataset\n",
    "# procesado\n",
    "df_FM_train = df_train[feats2use].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos las columans con las características, eliminando la columan target.\n",
    "columns_x = df_FM_train.columns.drop('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos las variables X e y, con los datos de entrenamiento y la variable\n",
    "# objetivo, respectivamente.\n",
    "X = df_FM_train[columns_x]\n",
    "y = df_FM_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UjuMwzPJX3Ww"
   },
   "outputs": [],
   "source": [
    "# Rellenar NaN con la media de cada columna\n",
    "X = df_train.fillna(X.mean())\n",
    "\n",
    "# Estandarizar las variables\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJIQZQvAc5EA"
   },
   "source": [
    "# 3 - Modelado\n",
    "---\n",
    "Una vez construido el dataset, se procede al entrenamiento de un modelo de Machine Learning.\n",
    "\n",
    "Con todo lo aprendido anteriormente de los datos, tratándose de un **problema de clasificación binaria**, con un dataset **desbalanceado**, un pequeño grupo de características a utilizar y claras agrupaciones que pueden ayudar en la decisión de la clase final, se ha decidido optar por un **XGBoost** como modelo para este proyecto.\n",
    "\n",
    "La decisión se ha tomado por la demostrada eficiencia de estos modelos en los problemas de clasificación binaria, en el tratamiento de datasets desbalanceados y en la capacidad de tratamiento de datos nulos como información desconocida.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_umap(features_np, min_dist=0, n_neighbours=50, n_components=2):\n",
    "    np.random.seed(SEED)\n",
    "    umap_reducer = umap.UMAP(\n",
    "        n_components=n_components,\n",
    "        min_dist = min_dist,\n",
    "        n_neighbors = n_neighbours,\n",
    "        metric='euclidean',\n",
    "        # random_state=SEED\n",
    "    )\n",
    "    data_umap = umap_reducer.fit_transform(features_np)\n",
    "\n",
    "    # Visualización de resultados de UMAP\n",
    "    if n_components == 2:\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.scatter(data_umap[:, 0], data_umap[:, 1], s=1, alpha=0.7)\n",
    "        plt.xlabel('Componente 1')\n",
    "        plt.ylabel('Componente 2')\n",
    "    else:\n",
    "        # Crear una figura 3D\n",
    "        fig = plt.figure(figsize=(10, 7))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "        # Dibujar el scatter plot\n",
    "        ax.scatter(data_umap[:, 0], data_umap[:, 1], data_umap[:, 2], s=1, alpha=0.7)\n",
    "\n",
    "        # Etiquetas de los ejes\n",
    "        ax.set_xlabel('Componente 1')\n",
    "        ax.set_ylabel('Componente 2')\n",
    "        ax.set_zlabel('Componente 3')\n",
    "\n",
    "        # Definir una vista específica (ángulo de elevación y azimut)\n",
    "        ax.view_init(elev=30, azim=120)\n",
    "\n",
    "    plt.title(f'Visualización de datos reducidos con UMAP (min_dist = {min_dist}, n_neighbours = {n_neighbours})')\n",
    "    # Mostrar el gráfico\n",
    "    plt.show()\n",
    "\n",
    "    return data_umap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 - Proyección del dataset en 2 dimensiones con UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos los parámetros iniciales de UMAP\n",
    "MIN_DIST = 0.01\n",
    "N_NEIGH = 45\n",
    "#N_NEIGH = 50\n",
    "N_COMPONENTS = 2\n",
    "SEED = 1234\n",
    "\n",
    "df_umap = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculando UMAP\")\n",
    "\n",
    "# Calcular el resultado de UMAP y guardarlo\n",
    "umap_result = draw_umap(X_scaled, MIN_DIST, N_NEIGH, N_COMPONENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ehJ9_3XnnJ0"
   },
   "source": [
    "## 3.1 - Entrenamiento del modelo HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Sugerir hiperparámetros\n",
    "    mc = trial.suggest_int('min_cluster_size', 15, 500)\n",
    "    ms = trial.suggest_int('min_samples', 15, 250)\n",
    "\n",
    "    clusterer = hdbscan.HDBSCAN(\n",
    "        min_cluster_size=mc, \n",
    "        min_samples=ms,\n",
    "        metric='euclidean',\n",
    "        cluster_selection_method='eom',\n",
    "        gen_min_span_tree=True,\n",
    "    )\n",
    "    \n",
    "    # Ajustar y predecir clusters\n",
    "    cluster_labels = clusterer.fit_predict(umap_result)\n",
    "    \n",
    "    # Filtrar puntos no ruidosos\n",
    "    valid_indices = cluster_labels != -1\n",
    "    cluster_labels_valid = cluster_labels[valid_indices]\n",
    "\n",
    "    # Evitar configuración con pocos o demasiados clusters\n",
    "    num_clusters = len(set(cluster_labels_valid))\n",
    "\n",
    "    # Calcular el validity\n",
    "    score = clusterer.relative_validity_\n",
    "    del clusterer\n",
    "    \n",
    "    #if (num_clusters == 9):\n",
    "    #    return score + 0.1\n",
    "    if (num_clusters < 7) or (num_clusters > 10):\n",
    "        return score - 0.3\n",
    "    \n",
    "    return score  # Maximizar la métrica\n",
    "\n",
    "# Ejecutar optimización\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=SEED))\n",
    "study.optimize(objective, n_trials=500)\n",
    "\n",
    "# Mejores parámetros\n",
    "print(\"Mejores parámetros:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En base a la exploración anterior, definimos los mejores hiperparámetros del HDBSCAN\n",
    "best_min_cluster_size = 33\n",
    "best_min_samples = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos HDBSCAN a nuestro dataframe de umap\n",
    "clusterer = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=best_min_cluster_size, \n",
    "    min_samples=best_min_samples,\n",
    "    gen_min_span_tree=True\n",
    ")\n",
    "\n",
    "cluster_labels = clusterer.fit_predict(umap_result)\n",
    "\n",
    "# Añadir `umap_result` y `cluster_labels` al DataFrame original utilizando el índice\n",
    "df_umap['cluster'] = cluster_labels\n",
    "\n",
    "print(f\"Número de clusters {df_umap[df_umap['cluster'] != -1]['cluster'].nunique()}\")\n",
    "print(f\"Validity score: {clusterer.relative_validity_:.2}\")\n",
    "\n",
    "X = np.array(umap_result)\n",
    "\n",
    "# Filtrar los puntos que no son ruido\n",
    "valid_indices = cluster_labels != -1 \n",
    "X_valid = X[valid_indices]\n",
    "cluster_labels_valid = cluster_labels[valid_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Uso de UMAP para proyectar los clústers generados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_clusters = np.unique(cluster_labels_valid)\n",
    "cluster_colors = {\n",
    "    0 : \"#1f77b4\",  # azul\n",
    "    1 : \"#ff7f0e\",  # naranja\n",
    "    2 : \"#2ca02c\",  # verde\n",
    "}\n",
    "\n",
    "\n",
    "valid_umap_result = umap_result[cluster_labels != -1]\n",
    "\n",
    "# Visualizamos los clusters\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "point_colors = np.array([cluster_colors[label] if label in cluster_colors else \"#d3d3d3\" for label in cluster_labels_valid])\n",
    "\n",
    "if N_COMPONENTS == 2:\n",
    "    scatter = plt.scatter(valid_umap_result[:, 0], valid_umap_result[:, 1], s=1, c=point_colors)\n",
    "    plt.xlabel('Componente 1')\n",
    "    plt.ylabel('Componente 2')\n",
    "else:\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Dibujar el scatter plot\n",
    "    scatter = ax.scatter(valid_umap_result[:, 0], valid_umap_result[:, 1], valid_umap_result[:, 2], c=cluster_labels[cluster_labels != -1], s=1, cmap=cmap)\n",
    "\n",
    "    # Etiquetas de los ejes\n",
    "    ax.set_xlabel('Componente 1')\n",
    "    ax.set_ylabel('Componente 2')\n",
    "    ax.set_zlabel('Componente 3')\n",
    "\n",
    "    # Definir una vista específica (ángulo de elevación y azimut)\n",
    "    ax.view_init(elev=30, azim=160)\n",
    "\n",
    "plt.title('Visualización de clusters con HDBSCAN')\n",
    "\n",
    "handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=8) \n",
    "           for label, color in cluster_colors.items()]\n",
    "labels = [f'Clúster {label}' if label != -1 else \"Ruido\" for label in cluster_colors.keys()]\n",
    "plt.legend(handles, labels, title=\"Clúster\", loc=\"center left\", bbox_to_anchor=(1.05, 0.5), ncol=1)\n",
    "\n",
    "# Añadir la leyenda\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos cuantos puntos han sido clasificados como ruido\n",
    "n_noise = list(cluster_labels).count(-1)\n",
    "print(f\"El número de puntos clasificados como ruido es: {n_noise}\")\n",
    "print(f\"lo que representa un {n_noise/len(cluster_labels)*100:.2f}% del total de puntos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFnGL1SfnnJ3"
   },
   "source": [
    "# 4 - Evaluación del modelo obtenido\n",
    "---\n",
    "En este último punto, procedemos a evaluar el modelo entrenado. Para ello, cabe resaltar que las métricas para modelos de clusterización son referenciales para varios entrenamientos sobre el mismo conjunto de datos, y una evaluación funcional y gráfica suele dar una mejor visión de la virtud del funcionamiento del modelo. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = df_target_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics['prediction'] = list(cluster_labels.astype(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics['prediction'] = df_metrics['prediction'].map({-1: -1, 0: 1, 1: 2, 2: 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "executionInfo": {
     "elapsed": 371,
     "status": "ok",
     "timestamp": 1700822434445,
     "user": {
      "displayName": "Manuel Díaz",
      "userId": "13859083903242049446"
     },
     "user_tz": -60
    },
    "id": "P_73eRcD5vRH",
    "outputId": "822a9ecd-98c2-4bdf-f9f7-db317f2b6f7d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(df_metrics['class'], df_metrics['prediction'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
