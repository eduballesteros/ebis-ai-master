{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8ed3875",
   "metadata": {},
   "source": [
    "# Ejemplo práctico de una red neuronal construida a mano\n",
    "---\n",
    "\n",
    "Autor: Manuel Díaz Bendito"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d5f8a4",
   "metadata": {},
   "source": [
    "# 0 - Instalaciones necesarias e importación de librerías utilizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50c4646",
   "metadata": {},
   "source": [
    "## Instalación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48fce326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting keras\n",
      "  Downloading keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting absl-py (from keras)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\balle\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from keras) (2.3.4)\n",
      "Collecting rich (from keras)\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting h5py (from keras)\n",
      "  Downloading h5py-3.15.1-cp313-cp313-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting optree (from keras)\n",
      "  Downloading optree-0.17.0-cp313-cp313-win_amd64.whl.metadata (34 kB)\n",
      "Collecting ml-dtypes (from keras)\n",
      "  Downloading ml_dtypes-0.5.3-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\balle\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from keras) (25.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\balle\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from optree->keras) (4.15.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\balle\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from rich->keras) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 17.5 MB/s  0:00:00\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading h5py-3.15.1-cp313-cp313-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.9/2.9 MB 36.1 MB/s  0:00:00\n",
      "Downloading ml_dtypes-0.5.3-cp313-cp313-win_amd64.whl (208 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.17.0-cp313-cp313-win_amd64.whl (316 kB)\n",
      "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, optree, ml-dtypes, mdurl, h5py, absl-py, markdown-it-py, rich, keras\n",
      "\n",
      "   ---- ----------------------------------- 1/9 [optree]\n",
      "   ---- ----------------------------------- 1/9 [optree]\n",
      "   ---- ----------------------------------- 1/9 [optree]\n",
      "   ---- ----------------------------------- 1/9 [optree]\n",
      "   -------- ------------------------------- 2/9 [ml-dtypes]\n",
      "   ------------- -------------------------- 3/9 [mdurl]\n",
      "   ----------------- ---------------------- 4/9 [h5py]\n",
      "   ----------------- ---------------------- 4/9 [h5py]\n",
      "   ----------------- ---------------------- 4/9 [h5py]\n",
      "   ----------------- ---------------------- 4/9 [h5py]\n",
      "   ----------------- ---------------------- 4/9 [h5py]\n",
      "   ----------------- ---------------------- 4/9 [h5py]\n",
      "   ----------------- ---------------------- 4/9 [h5py]\n",
      "   ----------------- ---------------------- 4/9 [h5py]\n",
      "   ----------------- ---------------------- 4/9 [h5py]\n",
      "   ----------------- ---------------------- 4/9 [h5py]\n",
      "   ---------------------- ----------------- 5/9 [absl-py]\n",
      "   ---------------------- ----------------- 5/9 [absl-py]\n",
      "   ---------------------- ----------------- 5/9 [absl-py]\n",
      "   ---------------------- ----------------- 5/9 [absl-py]\n",
      "   -------------------------- ------------- 6/9 [markdown-it-py]\n",
      "   -------------------------- ------------- 6/9 [markdown-it-py]\n",
      "   -------------------------- ------------- 6/9 [markdown-it-py]\n",
      "   -------------------------- ------------- 6/9 [markdown-it-py]\n",
      "   -------------------------- ------------- 6/9 [markdown-it-py]\n",
      "   -------------------------- ------------- 6/9 [markdown-it-py]\n",
      "   -------------------------- ------------- 6/9 [markdown-it-py]\n",
      "   -------------------------- ------------- 6/9 [markdown-it-py]\n",
      "   -------------------------- ------------- 6/9 [markdown-it-py]\n",
      "   ------------------------------- -------- 7/9 [rich]\n",
      "   ------------------------------- -------- 7/9 [rich]\n",
      "   ------------------------------- -------- 7/9 [rich]\n",
      "   ------------------------------- -------- 7/9 [rich]\n",
      "   ------------------------------- -------- 7/9 [rich]\n",
      "   ------------------------------- -------- 7/9 [rich]\n",
      "   ------------------------------- -------- 7/9 [rich]\n",
      "   ------------------------------- -------- 7/9 [rich]\n",
      "   ------------------------------- -------- 7/9 [rich]\n",
      "   ------------------------------- -------- 7/9 [rich]\n",
      "   ------------------------------- -------- 7/9 [rich]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ----------------------------------- ---- 8/9 [keras]\n",
      "   ---------------------------------------- 9/9 [keras]\n",
      "\n",
      "Successfully installed absl-py-2.3.1 h5py-3.15.1 keras-3.12.0 markdown-it-py-4.0.0 mdurl-0.1.2 ml-dtypes-0.5.3 namex-0.1.0 optree-0.17.0 rich-14.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\balle\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c440a59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c71720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f1081e",
   "metadata": {},
   "source": [
    "## Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b39d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from skimage import measure\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb05a5f5",
   "metadata": {},
   "source": [
    "# 1 - Definición de funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33087686",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sigmoid\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of z\n",
    "\n",
    "    Arguments:\n",
    "    x -- A scalar or numpy array of any size.\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(z)\n",
    "    \"\"\"\n",
    "\n",
    "    s=1/(1+np.exp(-z))\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb76c807",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"### Initialize weights\"\"\"\n",
    "\n",
    "def initialize_weights(dim):\n",
    "    \"\"\"\n",
    "    This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.\n",
    "    \n",
    "    Argument:\n",
    "    dim -- size of the w vector we want (or number of parameters in this case)\n",
    "    \n",
    "    Returns:\n",
    "    w -- initialized vector of shape (dim, 1)\n",
    "    b -- initialized scalar (corresponds to the bias)\n",
    "    \"\"\"\n",
    "\n",
    "    w=np.zeros([dim,1])\n",
    "    b=0\n",
    "  \n",
    "    assert(w.shape == (dim, 1))\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e60069",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"### Forward and backward propagation\"\"\"\n",
    "\n",
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function and its gradient for the propagation explained in the assignment\n",
    "\n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (number of examples, num_px * num_px)\n",
    "    Y -- true \"label\" vector of size (1, number of examples)\n",
    "\n",
    "    Return:\n",
    "    cost -- negative log-likelihood cost for logistic regression\n",
    "    dw -- gradient of the loss with respect to w, thus same shape as w\n",
    "    db -- gradient of the loss with respect to b, thus same shape as b\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    \n",
    "    # FORWARD PROPAGATION (FROM X TO COST)\n",
    "   \n",
    "    Y_hat=sigmoid(np.dot(w.T,X.T)+b)\n",
    "    cost=np.sum(np.dot(np.log(Y_hat),Y.T)+np.dot(np.log(1-Y_hat),(1-Y.T)))\n",
    "    cost=-(1/m)*cost\n",
    "    \n",
    "    # BACKWARD PROPAGATION (TO FIND GRAD)\n",
    "   \n",
    "    dw=np.dot(X.T,(Y_hat-Y).T)/m\n",
    "    db=np.sum((Y_hat-Y))/m\n",
    "\n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d2037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"### Gradient descent\"\"\"\n",
    "\n",
    "def gradient_descent(w, b, X, Y, num_iterations, learning_rate):\n",
    "    \"\"\"\n",
    "    This function optimizes w and b by running a gradient descent algorithm\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of shape (num_px * num_px, number of examples)\n",
    "    Y -- true \"label\" vector of shape (1, number of examples)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    \n",
    "    Returns:\n",
    "    params -- dictionary containing the weights w and bias b\n",
    "    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function\n",
    "    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.\n",
    "    \n",
    "    Tips:\n",
    "    You basically need to write down two steps and iterate through them:\n",
    "        1) Calculate the cost and the gradient for the current parameters. Use propagate().\n",
    "        2) Update the parameters using gradient descent rule for w and b.\n",
    "    \"\"\"\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        \n",
    "        # Cost and gradient calculation\n",
    "      \n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "      \n",
    "        # Retrieve derivatives from grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # update rule\n",
    "        \n",
    "        w=w-(learning_rate*dw)\n",
    "        b=b-(learning_rate*db)\n",
    "\n",
    "        # Record the costs\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            # Print the cost every 100 training examples\n",
    "            print (\"Cost after iteration %i: %f\" % (i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab3102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"### Make predictions\"\"\"\n",
    "\n",
    "def predict(w, b, X):\n",
    "    '''\n",
    "    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    Y_prediction = np.zeros((1, m))\n",
    "    w = w.reshape(X.shape[1], 1)\n",
    "    \n",
    "    # Compute vector \"A\" predicting the probabilities of the picture containing a 1\n",
    "    \n",
    "    A = sigmoid(np.dot(w.T, X.T) + b)\n",
    "    \n",
    "    \n",
    "    for i in range(A.shape[1]):\n",
    "        # Convert probabilities A[0,i] to actual predictions p[0,i]\n",
    "        if A[0][i]>=0.5:\n",
    "          Y_prediction[0][i]=1\n",
    "        else:\n",
    "          Y_prediction[0][i]=0\n",
    "\n",
    "\n",
    "    \n",
    "    assert(Y_prediction.shape == (1, m))\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c03c68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#Metrics calculators\"\"\"\n",
    "\n",
    "def TP_calculator(y,y_hat):\n",
    "  TP=0\n",
    "  for i in range(np.size(y)):\n",
    "    if y[i]==0 and y_hat[i]==0:\n",
    "      TP=TP+1\n",
    "  return TP\n",
    "\n",
    "def TN_calculator(y,y_hat):\n",
    "  TN=0\n",
    "  for i in range(np.size(y)):\n",
    "    if y[i]==1 and y_hat[i]==1:\n",
    "      TN=TN+1\n",
    "  return TN\n",
    "\n",
    "def FN_calculator(y,y_hat):\n",
    "  FN=0\n",
    "  for i in range(np.size(y)):\n",
    "    if y[i]==0 and y_hat[i]==1:\n",
    "      FN=FN+1\n",
    "  return FN\n",
    "\n",
    "def FP_calculator(y,y_hat):\n",
    "  FP=0\n",
    "  for i in range(np.size(y)):\n",
    "    if y[i]==1 and y_hat[i]==0:\n",
    "      FP=FP+1\n",
    "  return FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7c1021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_examples(x_data, y_data, num_examples=9):\n",
    "    # Select random indices\n",
    "    idx = np.random.choice(len(x_data), num_examples, replace=False)\n",
    "    selected_images = x_data[idx]\n",
    "    selected_labels = y_data[idx]\n",
    "\n",
    "    # Create a 3x3 grid plot\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(6,6))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for img, label, ax in zip(selected_images, selected_labels, axes):\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.set_title(f\"Label: {label}\")\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820a531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_examples(x_data, y_data, num_examples=100):\n",
    "    # Select random indices\n",
    "    idx = np.random.choice(len(x_data), num_examples, replace=False)\n",
    "    selected_images = x_data[idx]\n",
    "    selected_labels = y_data[idx]\n",
    "\n",
    "    # Create a 3x3 grid plot\n",
    "    fig, axes = plt.subplots(10, 10, figsize=(6,6))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for img, label, ax in zip(selected_images, selected_labels, axes):\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        #ax.set_title(f\"Label: {label}\")\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f378c2",
   "metadata": {},
   "source": [
    "# 2 - Carga de datos y preparación para el entrenamiento - Números 0 y 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e272bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "class0 = 0\n",
    "class1 = 1\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train[np.isin(y_train,[class0,class1]),:,:]\n",
    "y_train = 1*(y_train[np.isin(y_train,[class0,class1])]>class0)\n",
    "x_test = x_test[np.isin(y_test,[class0,class1]),:,:]\n",
    "y_test = 1*(y_test[np.isin(y_test,[class0,class1])]>class0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d565fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some examples\n",
    "plot_random_examples(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa00b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6d854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESHAPE\n",
    "\n",
    "x_train_flat = x_train.reshape(x_train.shape[0],-1)\n",
    "print(x_train_flat.shape)\n",
    "print('Train: '+str(x_train_flat.shape[0])+' images and '+str(x_train_flat.shape[1])+' neurons \\n')\n",
    "\n",
    "x_test_flat = x_test.reshape(x_test.shape[0],-1)\n",
    "print(x_test_flat.shape)\n",
    "print('Test: '+str(x_test_flat.shape[0])+' images and '+str(x_test_flat.shape[1])+' neurons \\n')\n",
    "\n",
    "# STRANDARIZE\n",
    "x_train_flat = x_train_flat / 255\n",
    "x_test_flat = x_test_flat / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f00fee",
   "metadata": {},
   "source": [
    "# 3 - Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade211d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c2351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"### Train the model (in training set)\"\"\"\n",
    "\n",
    "# Initialize parameters with zeros (≈ 1 line of code)\n",
    "w, b = initialize_weights(x_train_flat.shape[1])\n",
    "\n",
    "# Gradient descent (≈ 1 line of code)\n",
    "learning_rate = 0.005\n",
    "num_iterations = 2000\n",
    "parameters, grads, costs = gradient_descent(w, b, x_train_flat, y_train, 2000, 0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc5e37b",
   "metadata": {},
   "source": [
    "# 4 - Validación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9e74b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"### Test the model (in testing set)\"\"\"\n",
    "\n",
    "# Retrieve parameters w and b from dictionary \"parameters\"\n",
    "w = parameters[\"w\"]\n",
    "b = parameters[\"b\"]\n",
    "    \n",
    "# Predict test/train set examples (≈ 2 lines of code)\n",
    "y_prediction_test = predict(w, b, x_test_flat)\n",
    "y_prediction_train = predict(w, b, x_train_flat)\n",
    "\n",
    "# Print train/test Errors\n",
    "print('')\n",
    "print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_train - y_train)) * 100))\n",
    "print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))\n",
    "print('')\n",
    "\n",
    "plt.figure(figsize=(13,5))\n",
    "plt.plot(range(0,2000,100),costs)\n",
    "plt.title('Cost training vs iteration')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.xticks(range(0,2000,100))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(13,5))\n",
    "plt.imshow(w.reshape(28,28))\n",
    "plt.title('Template')\n",
    "\n",
    "TP=TP_calculator(y_test,np.squeeze(y_prediction_test))\n",
    "TN=TN_calculator(y_test,np.squeeze(y_prediction_test))\n",
    "FP=FP_calculator(y_test,np.squeeze(y_prediction_test))\n",
    "FN=FN_calculator(y_test,np.squeeze(y_prediction_test))\n",
    "\n",
    "AccTest=(TP+TN)/(TP+TN+FN+FP)\n",
    "print(\"Accuracy for testing data:\\n\", AccTest)\n",
    "SensTest=TP/(TP+FN)\n",
    "print(\"Sensitivity for testing data:\\n\", SensTest)\n",
    "SpecTest=TN/(TN+FP)\n",
    "print(\"Specificity for testing data:\\n\", SpecTest)\n",
    "BalancedAccTest=(SensTest + SpecTest)/2\n",
    "print(\"Balanced accuracy for testing data:\\n\", BalancedAccTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886ebcc1",
   "metadata": {},
   "source": [
    "# 5 - Carga de datos y preparación para el entrenamiento - Números 5 y 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc052ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## Merge functions and run your model now for 5 and 6\"\"\"\n",
    "\n",
    "# LOAD DATA\n",
    "class0 = 5\n",
    "class1 = 6\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train[np.isin(y_train,[class0,class1]),:,:]\n",
    "y_train = 1*(y_train[np.isin(y_train,[class0,class1])]>class0)\n",
    "x_test = x_test[np.isin(y_test,[class0,class1]),:,:]\n",
    "y_test = 1*(y_test[np.isin(y_test,[class0,class1])]>class0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0f9205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some examples\n",
    "plot_random_examples(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b30113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESHAPE\n",
    "\n",
    "x_train_flat = x_train.reshape(x_train.shape[0],-1)\n",
    "print(x_train_flat.shape)\n",
    "print('Train: '+str(x_train_flat.shape[0])+' images and '+str(x_train_flat.shape[1])+' neurons \\n')\n",
    "\n",
    "x_test_flat = x_test.reshape(x_test.shape[0],-1)\n",
    "print(x_test_flat.shape)\n",
    "print('Test: '+str(x_test_flat.shape[0])+' images and '+str(x_test_flat.shape[1])+' neurons \\n')\n",
    "\n",
    "# STRANDARIZE\n",
    "x_train_flat = x_train_flat / 255\n",
    "x_test_flat = x_test_flat / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac01e6ce",
   "metadata": {},
   "source": [
    "# 6 - Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f990c97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"### Train the model (in training set)\"\"\"\n",
    "\n",
    "# Initialize parameters with zeros (≈ 1 line of code)\n",
    "w, b = initialize_weights(x_train_flat.shape[1])\n",
    "\n",
    "# Gradient descent (≈ 1 line of code)\n",
    "learning_rate = 0.005\n",
    "num_iterations = 2000\n",
    "parameters, grads, costs = gradient_descent(w, b, x_train_flat, y_train, 2000, 0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0482d483",
   "metadata": {},
   "source": [
    "# 7 - Validación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dccea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"### Test the model (in testing set)\"\"\"\n",
    "\n",
    "# Retrieve parameters w and b from dictionary \"parameters\"\n",
    "w = parameters[\"w\"]\n",
    "b = parameters[\"b\"]\n",
    "    \n",
    "# Predict test/train set examples (≈ 2 lines of code)\n",
    "y_prediction_test = predict(w, b, x_test_flat)\n",
    "y_prediction_train = predict(w, b, x_train_flat)\n",
    "\n",
    "# Print train/test Errors\n",
    "print('')\n",
    "print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_train - y_train)) * 100))\n",
    "print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))\n",
    "print('')\n",
    "\n",
    "plt.figure(figsize=(13,5))\n",
    "plt.plot(range(0,2000,100),costs)\n",
    "plt.title('Cost training vs iteration')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.xticks(range(0,2000,100))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(13,5))\n",
    "plt.imshow(w.reshape(28,28))\n",
    "plt.title('Template')\n",
    "\n",
    "TP=TP_calculator(y_test,np.squeeze(y_prediction_test))\n",
    "TN=TN_calculator(y_test,np.squeeze(y_prediction_test))\n",
    "FP=FP_calculator(y_test,np.squeeze(y_prediction_test))\n",
    "FN=FN_calculator(y_test,np.squeeze(y_prediction_test))\n",
    "\n",
    "AccTest=(TP+TN)/(TP+TN+FN+FP)\n",
    "print(\"Accuracy for testing data:\\n\", AccTest)\n",
    "SensTest=TP/(TP+FN)\n",
    "print(\"Sensitivity for testing data:\\n\", SensTest)\n",
    "SpecTest=TN/(TN+FP)\n",
    "print(\"Specificity for testing data:\\n\", SpecTest)\n",
    "BalancedAccTest=(SensTest + SpecTest)/2\n",
    "print(\"Balanced accuracy for testing data:\\n\", BalancedAccTest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
