{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81ce4d93",
   "metadata": {},
   "source": [
    "Modelos GPT y estrategias de generación\n",
    "\n",
    "Notebook de apoyo con **2 ejercicios en Python** para hacer durante la clase:\n",
    "\n",
    "1. Laboratorio de **estrategias de decodificación** con un GPT pequeño.\n",
    "2. Laboratorio de **ablación de contexto en prompts**.\n",
    "\n",
    "Todo usando modelos open source (`distilgpt2`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d62eaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32487051",
   "metadata": {},
   "source": [
    "## Ejercicio 1 – Estrategias de decodificación con un GPT pequeño\n",
    "\n",
    "**Objetivo:** ver en la práctica cómo cambian las respuestas al usar greedy, sampling, distintas temperaturas, top-k y top-p.\n",
    "\n",
    "**Requisitos:**\n",
    "- `transformers`\n",
    "- `torch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989dcf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model_name = 'distilgpt2'  # pequeño y razonablemente rápido\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Configurar pad_token (distilgpt2 no tiene uno por defecto)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd950c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, **gen_kwargs):\n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "    # Añadir parámetros por defecto para evitar repetición excesiva\n",
    "    default_kwargs = {\n",
    "        'pad_token_id': tokenizer.eos_token_id,\n",
    "        'repetition_penalty': 1.1,  # Penaliza repetición\n",
    "    }\n",
    "    # Combinar con kwargs proporcionados (los kwargs del usuario tienen prioridad)\n",
    "    gen_kwargs = {**default_kwargs, **gen_kwargs}\n",
    "    with torch.no_grad():\n",
    "        out_ids = model.generate(**inputs, **gen_kwargs)\n",
    "    return tokenizer.decode(out_ids[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfe3cef",
   "metadata": {},
   "source": [
    "### 1.1. Comparación básica\n",
    "\n",
    "Probamos la misma frase inicial con varias configuraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d86ca0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT:\n",
      " In a distant future, humans and AI\n",
      "\n",
      "=== Greedy (do_sample=False) ===\n",
      "In a distant future, humans and AI will be able to create new worlds.\n",
      "The first step is to build the world of our own robots that can interact with each other in real time using their brains. The next stage involves building an artificial intelligence system called \"AI\" which could then work on any kind or form of human interaction between them. This would allow for more complex interactions such as social networking (like Facebook) where people are\n",
      "\n",
      "=== Sampling: temp=1.0, top_k=50 ===\n",
      "In a distant future, humans and AI will still share space with other homonin species. But this is where the question comes into play (though they do exist)—and if we get our hands on new ones to help humankind better understand their environment—it would likely be useful to find out what kinds of interactions you might have in common: how much time each person has spent communicating or when talking with others over an open Internet? What\n",
      "\n",
      "=== Sampling: temp=0.3, top_p=0.9 ===\n",
      "In a distant future, humans and AI will be able to do the same thing.\n"
     ]
    }
   ],
   "source": [
    "prompt = 'In a distant future, humans and AI'\n",
    "print('PROMPT:\\n', prompt)\n",
    "print('\\n=== Greedy (do_sample=False) ===')\n",
    "print(generate_text(prompt, max_new_tokens=80, do_sample=False))\n",
    "print('\\n=== Sampling: temp=1.0, top_k=50 ===')\n",
    "print(generate_text(prompt, max_new_tokens=80, do_sample=True, temperature=1.0, top_k=50))\n",
    "print('\\n=== Sampling: temp=0.3, top_p=0.9 ===')\n",
    "print(generate_text(prompt, max_new_tokens=80, do_sample=True, temperature=0.3, top_p=0.9))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7521abc1",
   "metadata": {},
   "source": [
    "### 1.2. Actividad\n",
    "\n",
    "**Nota:** `distilgpt2` está entrenado principalmente en inglés. Para prompts en español, considera usar un modelo multilingüe como `gpt2` con fine-tuning o modelos como `mGPT`.\n",
    "\n",
    "1. Cambia el `prompt` por uno diferente en inglés (historia, explicación técnica, etc.).\n",
    "2. Prueba temperaturas 0.1, 0.7 y 1.5 manteniendo el resto igual.\n",
    "3. Cambia `top_k` y `top_p` y comenta qué configuraciones dan textos más coherentes vs más creativos.\n",
    "4. Experimenta con `repetition_penalty` (valores entre 1.0 y 1.5) para controlar la repetición.\n",
    "5. Relaciona lo que observas con la teoría de decodificación vista en clase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa4ce71",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ejercicio 2 – Ablación de contexto en prompts\n",
    "\n",
    "**Objetivo:** ver cómo pequeñas modificaciones en el prompt (quitar instrucciones) cambian el comportamiento del modelo.\n",
    "\n",
    "Usaremos el mismo modelo `distilgpt2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54e22f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(prompt):\n",
    "    print('PROMPT:\\n', prompt)\n",
    "    print('\\nRESPUESTA:\\n')\n",
    "    print(generate_text(prompt, max_new_tokens=500, do_sample=True, temperature=0.7, top_p=0.9))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307242a3",
   "metadata": {},
   "source": [
    "### 2.1. Prompt completo\n",
    "\n",
    "**Nota importante:** `distilgpt2` está entrenado principalmente en inglés, por lo que los prompts en español pueden no funcionar bien. Este ejercicio muestra cómo el modelo responde a diferentes estructuras de prompt, incluso cuando el idioma no es óptimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0e89e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT:\n",
      " Answer in a professional tone, and summarize at the end in three bullet points. Topic: advantages of using Git in generative AI projects.\n",
      "\n",
      "RESPUESTA:\n",
      "\n",
      "Answer in a professional tone, and summarize at the end in three bullet points. Topic: advantages of using Git in generative AI projects.\n",
      "The following is an overview of how to use git for our project development purposes (i.e., from start-up). The topics will focus on some important things that need to be covered first as well as your own internal workings. For example, if you want to create new users or add their favorite apps just like we did with GitHub's ‪ Community‬s . You can also find other useful resources available here [1]. In general, this topic should not only cover advanced features such as support for shared libraries and tools but also about user experience — so please read these notes before discussing them!\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo con prompt en inglés (funciona mejor con distilgpt2)\n",
    "prompt_full = (\n",
    "    'Answer in a professional tone, and summarize at the end in three bullet points. '\n",
    "    'Topic: advantages of using Git in generative AI projects.'\n",
    ")\n",
    "gen(prompt_full)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4f6e9b",
   "metadata": {},
   "source": [
    "### 2.2. Variantes del prompt\n",
    "\n",
    "Ahora iremos quitando partes de la instrucción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af72a1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== Variant: without_bullets ===\n",
      "\n",
      "PROMPT:\n",
      " Answer in a professional tone. Topic: advantages of using Git in generative AI projects.\n",
      "\n",
      "RESPUESTA:\n",
      "\n",
      "Answer in a professional tone. Topic: advantages of using Git in generative AI projects.\n",
      "I’m not going to say that this is an absolute good idea, but I think it will be useful if you have questions about the nature and usefulness of git libraries or how they are used by developers on StackOverflow (and other forums).\n",
      "\n",
      "\n",
      "=== Variant: without_tone ===\n",
      "\n",
      "PROMPT:\n",
      " Answer, and summarize at the end in three bullet points. Topic: advantages of using Git in generative AI projects.\n",
      "\n",
      "RESPUESTA:\n",
      "\n",
      "Answer, and summarize at the end in three bullet points. Topic: advantages of using Git in generative AI projects.\n",
      "There are several issues that can be addressed here; one is it's not possible to use git as a whole without having multiple branches (for example, you have your own branch). This may cause some developers or programmers to switch back into different languages for reasons they do not want to know about them - but if there are people who think this might make sense then let me explain how these problems work with all sorts of other tools like Nginx etc. But I will talk briefly on each issue before we get going on what makes up those concerns... There were also many questions raised by various authors/developers regarding why GitHub was never included alongside any other code-base developed within an application such as JavaFX . However, because Github does require access to its repository every time someone installs their app onto another machine, which means when building applications from scratch, most likely no developer has ever used Git directly! We're looking forward to discussing both aspects more closely during our conversation next week so stay tuned !\n",
      "\n",
      "\n",
      "=== Variant: topic_only ===\n",
      "\n",
      "PROMPT:\n",
      " Advantages of using Git in generative AI projects.\n",
      "\n",
      "RESPUESTA:\n",
      "\n",
      "Advantages of using Git in generative AI projects.\n",
      "In the last few years, I have been working on some new software development tools that will help you get started with coding and other creative endeavors: Python or Django to make your own interactive web applications for yourself! This project has also received several contributions from various organizations including Open Data Research Foundation (OpenData) as well as others such Asimov's University of California at Berkeley; Microsoft Azure Development Center, Google Cloud Platforms (GPCS), Adobe Enterprise Linux Systems Group (FOSS), Cisco Advanced Computing System Security Lab (ACSI), IBM Office 365 Software Engineering Institute (IBM-AIS), Gartner Labs (IAS), Oracle Corporation (ORC), Apache Web Services LLC (Apache 5). We believe this program can be used by any community organization like us who are interested in helping out developers more easily through their application deployment processes.\n"
     ]
    }
   ],
   "source": [
    "# Variantes del prompt en inglés (funciona mejor con distilgpt2)\n",
    "prompts = {\n",
    "    'without_bullets': 'Answer in a professional tone. Topic: advantages of using Git in generative AI projects.',\n",
    "    'without_tone': 'Answer, and summarize at the end in three bullet points. Topic: advantages of using Git in generative AI projects.',\n",
    "    'topic_only': 'Advantages of using Git in generative AI projects.',\n",
    "}\n",
    "\n",
    "for name, p in prompts.items():\n",
    "    print('\\n\\n=== Variant:', name, '===\\n')\n",
    "    gen(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a358f8",
   "metadata": {},
   "source": [
    "### 2.3. Actividad\n",
    "\n",
    "1. Cambia el tema (por ejemplo: *ethical risks of generative AI*, *MLOps best practices*, etc.).\n",
    "2. Añade nuevas instrucciones (por ejemplo: *avoid technical jargon*, *use concrete examples*, *respond in JSON format*).\n",
    "3. Observa qué instrucciones respeta mejor el modelo y cuáles ignora más a menudo.\n",
    "4. Prueba diferentes estructuras de prompt (preguntas directas, instrucciones explícitas, ejemplos few-shot).\n",
    "5. Piensa cómo diseñar prompts **más robustos** a partir de lo que ves.\n",
    "\n",
    "**Nota:** Si quieres trabajar con español, considera usar un modelo multilingüe o fine-tuneado en español."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
